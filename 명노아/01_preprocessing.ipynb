{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀파일 읽어들이기\n",
    "df = pd.read_excel('../data/야인시대 1부 (1~50) 통합대본.xlsx')\n",
    "df2 = pd.read_excel('../data/야인시대 2부(51~124) 통합대본.xlsx')\n",
    "df= pd.concat([df, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인물 컬럼에서 \"#\"으로 시작하는 행은 제거하는 코드 \n",
    "df = df[df[\"인물\"].str.startswith(\"#\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "인물\n",
       "두한      5677\n",
       "이정재     2158\n",
       "김영태     1803\n",
       "임화수     1492\n",
       "정진영     1314\n",
       "최동열     1141\n",
       "개코      1040\n",
       "김무옥      966\n",
       "미와       943\n",
       "문영철      861\n",
       "시라소니     828\n",
       "하야시      687\n",
       "조병옥      659\n",
       "곽영주      653\n",
       "이기붕      618\n",
       "신영균      611\n",
       "유지광      594\n",
       "이승만      585\n",
       "김기홍      584\n",
       "유진산      583\n",
       "나레이션     536\n",
       "이화룡      534\n",
       "삼수       497\n",
       "나미꼬      474\n",
       "구마적      471\n",
       "이석재      455\n",
       "원노인      442\n",
       "눈물       439\n",
       "설향       342\n",
       "김관철      341\n",
       "친할머니     341\n",
       "쌍칼       337\n",
       "번개       335\n",
       "정대발      333\n",
       "애란       294\n",
       "오숙근      293\n",
       "김동진      289\n",
       "김천호      284\n",
       "이억일      276\n",
       "정팔       272\n",
       "한백수      272\n",
       "장택상      268\n",
       "이영숙      266\n",
       "소년개코     265\n",
       "왕발       258\n",
       "마루오까     253\n",
       "조열승      228\n",
       "박인애      227\n",
       "오무라      227\n",
       "와싱턴      225\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people=list(df[\"인물\"].value_counts()[:50].index) # 대사가 많은 인물만 추리기 \n",
    "\n",
    "\n",
    "# 두한, 청년두한, 소년두한\n",
    "# 정진영, 청년진영 \n",
    "# 개코, 소년개코 \n",
    "# 해당 인물을 같은 라벨로 표시하기 : replace사용\n",
    "replace_dict = {\n",
    "    \"청년두한\": \"두한\",\n",
    "    \"소년두한\": \"두한\",\n",
    "    \"청년진영\": \"정진영\",\n",
    "    \"청년개코\": \"개코\"\n",
    "}\n",
    "\n",
    "df[\"인물\"] = df[\"인물\"].replace(replace_dict)\n",
    "df[\"인물\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긴 문장만 남기기\n",
    "\n",
    "df = df[df[\"대사\"].str.len() > 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29369 entries, 2 to 35723\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   회차      29369 non-null  int64 \n",
      " 1   시간      29369 non-null  object\n",
      " 2   인물      29369 non-null  object\n",
      " 3   대사      29369 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        회차     시간    인물                                                 대사\n",
      "2        1    0~5  나레이션  이 이야기는 암울했던 민족의 수난기와 격동기의 역사를 살다 갔던 영원한 야인 김두한...\n",
      "3        1    0~5  나레이션  그러나 드라마의 원만한 진행을 위하여 시대와 역사적 상황을 운영하는 인물 일부분에서...\n",
      "7        1    0~5   최동열                     으응 너무 늦었어 요즘 통 날씨가 좋지 않아서 미뤘더니\n",
      "9        1    0~5   최동열  흐흐흐 흙이 좋은 것이겠지 정치를 그만 두겠다고 했던가 국회의원이 정치를 그만두면 ...\n",
      "11       1    0~5   최동열                    별장 자네가 무슨 별장이 허 허허허 혹시 교도소 얘기인가\n",
      "...    ...    ...   ...                                                ...\n",
      "35718  124  55~60  나레이션  많은 인파가 몰린 그의 장례 행렬에는 한 무리의 어린 아이들도 그 뒤를 잇고 있었다...\n",
      "35720  124  60~65  나레이션  김두한 그는 일제 말 우리가 주권을 잃었던 식민지 시절부터 해방 이후 좌우익의 대립...\n",
      "35721  124  60~65   최동열  나는 오랫동안 자네를 지켜보아 온 사람일세 자네는 자네답게 살았어 조선의 주먹 황제...\n",
      "35722  124  60~65   최동열  나름대로 자네의 역사를 가지고 자네의 시대를 치열하고 열심히 살았다는 얘기야 뭐랄까...\n",
      "35723  124  60~65  나레이션  야인시대 그렇다 그것은 바로 그가 몸바쳐 살아왔던 이 나라 격동기의 또 다른 역사의...\n",
      "\n",
      "[29369 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_korean_words(text):\n",
    "    korean_words = re.findall(r\"[가-힣]+\", text)\n",
    "    return ' '.join(korean_words)\n",
    "\n",
    "# \"대사\" 열에 함수 적용하여 추출된 한글 단어들을 공백으로 구분하여 하나의 문자열로 변환하여 저장\n",
    "df[\"대사\"] = df[\"대사\"].apply(extract_korean_words)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        이 이야기는 암울했던 민족의 수난기와 격동기의 역사를 살다 갔던 영원한 야인 김두한...\n",
       "3        그러나 드라마의 원만한 진행을 위하여 시대와 역사적 상황을 운영하는 인물 일부분에서...\n",
       "7                           으응 너무 늦었어 요즘 통 날씨가 좋지 않아서 미뤘더니\n",
       "9        흐흐흐 흙이 좋은 것이겠지 정치를 그만 두겠다고 했던가 국회의원이 정치를 그만두면 ...\n",
       "11                         별장 자네가 무슨 별장이 허 허허허 혹시 교도소 얘기인가\n",
       "                               ...                        \n",
       "35718    많은 인파가 몰린 그의 장례 행렬에는 한 무리의 어린 아이들도 그 뒤를 잇고 있었다...\n",
       "35720    김두한 그는 일제 말 우리가 주권을 잃었던 식민지 시절부터 해방 이후 좌우익의 대립...\n",
       "35721    나는 오랫동안 자네를 지켜보아 온 사람일세 자네는 자네답게 살았어 조선의 주먹 황제...\n",
       "35722    나름대로 자네의 역사를 가지고 자네의 시대를 치열하고 열심히 살았다는 얘기야 뭐랄까...\n",
       "35723    야인시대 그렇다 그것은 바로 그가 몸바쳐 살아왔던 이 나라 격동기의 또 다른 역사의...\n",
       "Name: 대사, Length: 29369, dtype: object"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"대사\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "people=['두한',\n",
    " '이정재',\n",
    " '정진영',\n",
    " '이승만'\n",
    "]\n",
    "df=df[df[\"인물\"].isin(people)].reset_index(drop=True)\n",
    "df.to_csv('../data/야인시대.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df[\"인물\"]\n",
    "feature = df[\"대사\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['두한' '정진영' '이정재' '이승만']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 1])"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 을 인코딩하기\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "print(df[\"인물\"].unique())\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(label)\n",
    "label = encoder.transform(label)\n",
    "df[\"인물\"]=label\n",
    "df[\"인물\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, corpus):\n",
    "        nsmcDF = pd.DataFrame(corpus).fillna('')\n",
    "\n",
    "        x_data = nsmcDF['대사'].values\n",
    "        self.x_data = x_data\n",
    "        self.y_data = nsmcDF['인물'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDS = CustomDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5120"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 토큰관련 특별 문자\n",
    "UNK = '<UNK>'\n",
    "PAD = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran,Okt\n",
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Install MeCab in order to use it: http://konlpy.org/en/latest/install/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\konlpy\\tag\\_mecab.py:77\u001b[0m, in \u001b[0;36mMecab.__init__\u001b[1;34m(self, dicpath)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagger \u001b[38;5;241m=\u001b[39m \u001b[43mTagger\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-d \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m dicpath)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtagset \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/data/tagset/mecab.json\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m utils\u001b[38;5;241m.\u001b[39minstallpath)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Tagger' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[640], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### 토큰화 인스턴스 생성\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mMecab\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\konlpy\\tag\\_mecab.py:82\u001b[0m, in \u001b[0;36mMecab.__init__\u001b[1;34m(self, dicpath)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe MeCab dictionary does not exist at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Is the dictionary correctly installed?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mYou can also try entering the dictionary path when initializing the Mecab class: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMecab(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m/some/dic/path\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m dicpath)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstall MeCab in order to use it: http://konlpy.org/en/latest/install/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Install MeCab in order to use it: http://konlpy.org/en/latest/install/"
     ]
    }
   ],
   "source": [
    "### 토큰화 인스턴스 생성\n",
    "tokenizer =Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for label, text in data_iter:\n",
    "        yield (token for token in tokenizer.morphs(text) if len(token) >= 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = build_vocab_from_iterator( yield_tokens(trainDS), min_freq=2, specials= [PAD, UNK],special_first=True)\n",
    "VOCAB.set_default_index(VOCAB[UNK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<PAD>', '<UNK>', '이', '을', '들', '가', '에', '은', '를'], 1)"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### VOCAB 메서드 \n",
    "VOCAB.get_itos()[:9],  VOCAB.get_stoi()[UNK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>',\n",
       " '<UNK>',\n",
       " '이',\n",
       " '을',\n",
       " '들',\n",
       " '가',\n",
       " '에',\n",
       " '은',\n",
       " '를',\n",
       " '말',\n",
       " '는',\n",
       " '이야',\n",
       " '한',\n",
       " '그',\n",
       " '도',\n",
       " '아',\n",
       " '것',\n",
       " '의',\n",
       " '내',\n",
       " '우리',\n",
       " '거',\n",
       " '다',\n",
       " '사람',\n",
       " '입니다',\n",
       " '거야',\n",
       " '일',\n",
       " '나',\n",
       " '할',\n",
       " '해',\n",
       " '으로',\n",
       " '야',\n",
       " '잘',\n",
       " '그래',\n",
       " '게',\n",
       " '안',\n",
       " '두',\n",
       " '지금',\n",
       " '고',\n",
       " '저',\n",
       " '하고',\n",
       " '하는',\n",
       " '일이',\n",
       " '에서',\n",
       " '생각',\n",
       " '뭐',\n",
       " '하',\n",
       " '그렇게',\n",
       " '수',\n",
       " '못',\n",
       " '로',\n",
       " '좀',\n",
       " '그리고',\n",
       " '과',\n",
       " '형님',\n",
       " '서',\n",
       " '김두한',\n",
       " '요',\n",
       " '하하',\n",
       " '있는',\n",
       " '겁니다',\n",
       " '만',\n",
       " '난',\n",
       " '니까',\n",
       " '어떻게',\n",
       " '그런',\n",
       " '정말',\n",
       " '제',\n",
       " '더',\n",
       " '무슨',\n",
       " '놈',\n",
       " '알',\n",
       " '예',\n",
       " '와',\n",
       " '이제',\n",
       " '왜',\n",
       " '자',\n",
       " '적',\n",
       " '까지',\n",
       " '나라',\n",
       " '때',\n",
       " '너',\n",
       " '님',\n",
       " '전',\n",
       " '이렇게',\n",
       " '에게',\n",
       " '아니',\n",
       " '이오',\n",
       " '하지만',\n",
       " '있어',\n",
       " '봐',\n",
       " '오늘',\n",
       " '얘기',\n",
       " '있습니다',\n",
       " '친구',\n",
       " '하지',\n",
       " '여기',\n",
       " '위해',\n",
       " '건',\n",
       " '이다',\n",
       " '당신']"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.get_itos()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 텍스트 >>>> 정수 인코딩\n",
    "text_pipeline = lambda x: VOCAB(tokenizer.morphs(x))\n",
    "\n",
    "### ===> 레이틀 >>> 정수 인코딩 (0~3)\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 인코딩 : 문자 >>>> 숫자로 변환\n",
    "token_to_id ={ label : id  for label, id in VOCAB.get_stoi().items()}\n",
    "\n",
    "### 디코딩 : 숫자 >>>> 문자로 변환\n",
    "id_to_token ={ id : label  for label, id in VOCAB.get_stoi().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 모듈로딩\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 실행 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    \n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num_train :4864\n",
      " len(split_trainDS) :4864\n",
      " len(split_validDS) :256\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "num_train = int(len(trainDS) * 0.90)\n",
    "print(f' num_train :{num_train}')\n",
    "\n",
    "split_trainDS, split_validDS= random_split( trainDS, [num_train, len(trainDS) - num_train])\n",
    "print(f' len(split_trainDS) :{len(split_trainDS)}')\n",
    "print(f' len(split_validDS) :{len(split_validDS)}')\n",
    "\n",
    "trainDL = DataLoader( split_trainDS, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch )\n",
    "validDL = DataLoader( split_validDS, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x1f80861a460>"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " len(trainDL) :4864\n",
      " len(validDL) :256\n"
     ]
    }
   ],
   "source": [
    "print(f' len(trainDL) :{len(trainDL)*BATCH_SIZE}')\n",
    "print(f' len(validDL) :{len(validDL)*BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([2, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 3, 2, 3, 2, 2, 0,\n",
      "        3, 0, 2, 2, 0, 2, 0, 1]), tensor([   2,   20, 4409,  325,  279, 1585,  153,  371,  324,  375, 2562,   22,\n",
      "           4,    7,  213,  225, 4369, 1232,  101,  941,  123,  202,   18,    5,\n",
      "         150,    3,  590,    1,    1,   36,    2,   78,    5,   63,    1,   25,\n",
      "         324,   69,    4,   84,    1,   22,    3,  321,   53,   29, 4272,   47,\n",
      "          10,  142,  900,  502,   76,    7,  294,  379,    1,  900,   38,   14,\n",
      "         792,   18,  558,   23,  372,   77,  412,   27,   47, 1407, 1320,  149,\n",
      "          31,  664,   21,   51,  147,  131,    8,   20, 1970,   58,  374,  395,\n",
      "          23,   83,    4,  513,   18,    5, 2844, 2759, 1009,  828,  887,  172,\n",
      "         127, 1104, 4072,  887,  172,  127,   56,    1,    1,    1,  311,    2,\n",
      "        5120,  963,  151,  913,  245,  757,   17,  259,   52, 3380, 3533,  115,\n",
      "          60,   12,  116,    6, 5011, 1809,   28,   13,  173,   42,  155, 1390,\n",
      "           8,    1, 1485,  580,  675,    1, 2583,   19,    1,    2,  306, 2061,\n",
      "           8, 2268,   37, 2548,  698,  335,   79,  508,    4,    3,   39,    1,\n",
      "           2,    9,   23, 2369,   42, 2088, 1155, 1462,  539,  139,   21,   19,\n",
      "         782,    7,  937,  154,   18,    6,  826, 1262,    7, 3355, 2088,  221,\n",
      "         115,   16, 4937,  273, 1938, 1017,  896,  202,    7, 5211,   14, 4462,\n",
      "         178,   17, 4058,    8,  678,    7,    2,  116,    6,    1, 2241,   34,\n",
      "         407,  348, 1035, 1102,   34,  521,   34,  521,   34,  521,  256,   19,\n",
      "         405,    5, 1231,   20,  406,  996,    6,  308,   12,  156,   11,   51,\n",
      "          19,  286,  662, 1452,  499,    5, 1234,  286,   29,    1,  156, 1153,\n",
      "         156,    3,    1,  130,   29,   31, 3500,  496,  156,  947,  404, 2378,\n",
      "          97,  252,   20,  188,    1,    1,   13,    1,    8,   21,   94,   48,\n",
      "          40, 1701,    7, 4299,    1,    1,   22,   29,  108,  193,   17, 1658,\n",
      "           3,  218,    1,    2,    9,   23, 1115,   69,    4,   11,  201,    4,\n",
      "          26,   55,   11,  201,    4,  204,   30,   44,   40,   69,    4,   11,\n",
      "           1,   70,   33, 1555,  168,   26,  332,  604,    1,  172, 1976,    6,\n",
      "           1, 1724, 1443, 1401,   28, 1650,  638,    5,  473,  638,    8,    1,\n",
      "        1184,    6, 1004,  126,   16,   29,  440,  891,  765,  392, 1114,    5,\n",
      "         112,  439,    7,    1,    2, 1449, 2569,   24, 5072,   75,  628,  796,\n",
      "         491,  491, 2600,   14, 3874, 2275, 2895, 1267, 1303, 2428,   21,    4,\n",
      "          18,    5, 1143, 1855,  225,   88,   31,    4,  453,  177,  424,   47,\n",
      "         141, 1189,    1,   15,  926,    6, 1957,    1,   36,  478,    1,    1,\n",
      "          54,   37,  784,  457,    2,  652, 3055,   24,  140,    1,   29, 1965,\n",
      "        5158,   19,  721,    3, 2239,   39,  526, 1664,   52,  156,    3,  338,\n",
      "        4018,   29,    1,   33,  258,   72,  113,   17, 2828,   23,  367,  279,\n",
      "           3,  320,  255,   84, 4398,   36,    7,   19,    5, 4504,   33, 5116,\n",
      "          19,  118,    5, 4504,  353,    9,   23,  518,  118,    4,  881,   19,\n",
      "           5,  176,    3, 5357,  328,    3,  176,    3, 1276, 4649,    1,   97,\n",
      "         290,   16,   14,  136,  327,   84,  222,  109, 2193, 2436,   13,  439,\n",
      "           7,  155,  770,  992,  537,   30,   87, 1019,   82, 1712,  381, 3068,\n",
      "           5,  126,  149,   49,   70,   37,    1,  100, 1019,   13,   91,    8,\n",
      "          39,   58,  238,  972,   20,  309,  110,    1,   32,  254,  149,  983,\n",
      "        2754,  227,  473,  409,   84,  154,   52,  387, 1046,    8, 5055,  166,\n",
      "         293, 3509,   48,  272,    1,  181,   24,    1, 2262,    9,   11,    2,\n",
      "          89,  527,   30,  288,   10,    2, 1173,   17, 3363,   11,  293,    1,\n",
      "          16, 3043, 3469,   12,   24,    2, 1288,    1,   11,   18,  405,    5,\n",
      "           1,  414,  191, 3276,  234,  326, 1351,  785,  426,    2,  215, 3275,\n",
      "         477,  759,  198,   26,   10,   13,   93,    8,    1,  626,  236,   12,\n",
      "         129,  585,    8, 2700,    1, 1225,  700,    2, 3493, 1451,   76,  605,\n",
      "           3,   63, 1050, 1388,   16,  146,   36,  506,   17,  104,  781,    8,\n",
      "           1,   38,  278,   72, 1505, 1006,    8,   68, 4575, 2418, 1388,   47,\n",
      "        1220,    9,  146,  647,    5,  147,   22,  132,   10,   81, 1222,    1,\n",
      "          16,    2,  234,   17, 1112, 1625]), tensor([  0,  11,  35,  58,  85,  94, 103, 139, 159, 196, 208, 221, 243, 256,\n",
      "        282, 300, 317, 333, 344, 351, 369, 392, 418, 439, 474, 487, 500, 516,\n",
      "        549, 564, 581, 615]))\n"
     ]
    }
   ],
   "source": [
    "for i in trainDL:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self, VOCAB_SIZE, EMBEDD_DIM, HIDDEN_SIZE, NUM_CLASS):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(VOCAB_SIZE, EMBEDD_DIM, sparse=False)\n",
    "        self.hidden = nn.Linear(EMBEDD_DIM, HIDDEN_SIZE)\n",
    "        self.fc = nn.Linear(HIDDEN_SIZE, NUM_CLASS)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.hidden.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        hidden_output = F.relu(self.hidden(embedded))\n",
    "        output = self.fc(hidden_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 관련 파라미터와 인스턴스 \n",
    "HIDDEN_SIZE=16\n",
    "EMBEDD_DIM=64\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "NUM_CLASS = 4\n",
    "EPOCHS = 10\n",
    "LR = 0.1\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 관련 인스턴스\n",
    "import torch.optim as optim\n",
    "MODEL = TextModel(VOCAB_SIZE, EMBEDD_DIM, HIDDEN_SIZE, NUM_CLASS).to(device)\n",
    "CRITERION = nn.CrossEntropyLoss()\n",
    "OPTIMIZER = optim.AdamW(MODEL.parameters(), lr=LR)\n",
    "SCHEDULER = optim.lr_scheduler.StepLR(OPTIMIZER, 1.0, gamma=0.1) # learning rate를 줄이는 용도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    total_acc, total_count = 0,0\n",
    "    log_interval=100\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    \n",
    "    for idx, (label, text, offsets) in pbar:\n",
    "        predicted_label = model(text, offsets)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        \n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            print(f\"epoch : {epoch} batch : {idx} loss : {loss.item()}\")\n",
    "            print(f\"Accuracy : {total_acc/total_count}\")\n",
    "            total_acc, total_count = 0,0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    total_acc, total_count = 0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            \n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 101/152 [00:11<00:05,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 batch : 100 loss : 0.6878868937492371\n",
      "Accuracy : 0.5659034653465347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 Accuracy : 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 102/152 [00:10<00:05,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2 batch : 100 loss : 0.7305158376693726\n",
      "Accuracy : 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2 Accuracy : 0.64453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 101/152 [00:10<00:04, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3 batch : 100 loss : 0.5382252931594849\n",
      "Accuracy : 0.7920792079207921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3 Accuracy : 0.6953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 102/152 [00:10<00:05,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4 batch : 100 loss : 1.0720224380493164\n",
      "Accuracy : 0.8168316831683168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4 Accuracy : 0.6484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 104/152 [00:10<00:04, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5 batch : 100 loss : 0.28500455617904663\n",
      "Accuracy : 0.8301361386138614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5 Accuracy : 0.671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 100/152 [00:10<00:05,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6 batch : 100 loss : 0.4856991767883301\n",
      "Accuracy : 0.8412747524752475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6 Accuracy : 0.6328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 100/152 [00:10<00:05,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7 batch : 100 loss : 1.0423462390899658\n",
      "Accuracy : 0.8084777227722773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7 Accuracy : 0.640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 102/152 [00:10<00:05,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8 batch : 100 loss : 0.4712865650653839\n",
      "Accuracy : 0.8567450495049505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:15<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8 Accuracy : 0.65625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 103/152 [00:10<00:04, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9 batch : 100 loss : 0.8515774011611938\n",
      "Accuracy : 0.8452970297029703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:15<00:00,  9.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9 Accuracy : 0.62109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 100/152 [00:10<00:05,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10 batch : 100 loss : 0.7317283749580383\n",
      "Accuracy : 0.8459158415841584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 152/152 [00:16<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10 Accuracy : 0.6171875\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(MODEL, trainDL, OPTIMIZER, CRITERION, epoch)\n",
    "    accu_val = evaluate(MODEL, validDL, CRITERION)\n",
    "    print(f\"epoch : {epoch} Accuracy : {accu_val}\")\n",
    "    #SCHEDULER.step()\n",
    "torch.save(MODEL, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text), dtype=torch.int64).to(device)\n",
    "        text = text.unsqueeze(0)\n",
    "        offsets = torch.tensor([0]).to(device)\n",
    "        predicted_label = model(text, offsets)\n",
    "        return predicted_label.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "if input is 2D, then offsets has to be None, as input is treated is a mini-batch of fixed length sequences. However, found offsets of type <class 'torch.Tensor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[593], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# predict 함수 테스트\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m아주 좋아요\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pipeline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m예측 : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[592], line 6\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, text, text_pipeline)\u001b[0m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m offsets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 6\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_label\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[586], line 27\u001b[0m, in \u001b[0;36mTextModel.forward\u001b[1;34m(self, text, offsets)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, offsets):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# 임베딩\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# 은닉층 활성화 함수 적용\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     hidden_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden(embedded))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:390\u001b[0m, in \u001b[0;36mEmbeddingBag.forward\u001b[1;34m(self, input, offsets, per_sample_weights)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, offsets: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, per_sample_weights: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of EmbeddingBag.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \n\u001b[0;32m    362\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m          returned vectors filled by zeros.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_bag\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mper_sample_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_last_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\TEXT_017_220_38\\lib\\site-packages\\torch\\nn\\functional.py:2376\u001b[0m, in \u001b[0;36membedding_bag\u001b[1;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001b[0m\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[0;32m   2375\u001b[0m         type_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(offsets))\n\u001b[1;32m-> 2376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif input is 2D, then offsets has to be None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, as input is treated is a mini-batch of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m fixed length sequences. However, found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2380\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffsets of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2381\u001b[0m     )\n\u001b[0;32m   2382\u001b[0m offsets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mnumel(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: if input is 2D, then offsets has to be None, as input is treated is a mini-batch of fixed length sequences. However, found offsets of type <class 'torch.Tensor'>"
     ]
    }
   ],
   "source": [
    "# predict 함수 테스트\n",
    "test_text = \"아주 좋아요\"\n",
    "predicted_label = predict(MODEL, test_text, text_pipeline)\n",
    "print(f\"예측 : {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 105, 5115,   79,    6,  689,    1,    1, 1647,   25,    4,    2,  516,\n",
      "            3, 2429, 1257,    8, 2178,    1,    1, 1384,   10,  325,  279,    2,\n",
      "            1,  378,    1]])\n",
      "예측 : 이정재\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    with torch.no_grad():\n",
    "        label_text = ['두한', '정진영', '이정재', '이승만']\n",
    "        text = torch.tensor(text_pipeline(text), dtype=torch.int64).to(device)\n",
    "        text = text.unsqueeze(0)\n",
    "        offsets = None\n",
    "        print(text)\n",
    "        predicted_label = MODEL(text, offsets)\n",
    "        print(f\"예측 : {label_text[predicted_label.argmax(1).item()]}\")\n",
    "\n",
    "\n",
    "predict(\"아주중요할때에신경쓰지도않았던작은일들이큰일을망치는경우를종종보았습니다.나머지는김고문이잘알아서하세요.\") # 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[816, 212, 202,   1,  38,  10, 229, 361, 765]])\n",
      "예측 : 정진영\n"
     ]
    }
   ],
   "source": [
    "predict(\"친애하는국민여러분,저는대통령이승만입네다\") # 틀림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[503,   1]])\n",
      "예측 : 이정재\n"
     ]
    }
   ],
   "source": [
    "predict(\"그래요?\") # 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[361]])\n",
      "예측 : 이정재\n"
     ]
    }
   ],
   "source": [
    "predict(\"이승만\") # 틀림 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,  242,   14, 4655,    1, 1023,   14, 4655,   73,  452,    4,   84,\n",
      "         3650,    3, 1919,   89,    1,  512,    1,    1,  792,    4,   28,  166,\n",
      "            1,   95,  283,  928,   81, 3396,    1,   19,  131,    4, 1099,    2,\n",
      "            1, 3631,   60,  416,    1, 2245,    2,    1]])\n",
      "예측 : 두한\n"
     ]
    }
   ],
   "source": [
    "predict(\"이정치도썩고,사회도썩고이제학생들에게희망을가져봐야하지않겠습니까?어인사들해라.여기영태형님이시고,우리식구들신영균이,홍만길이,홍영철이.\") # 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 477,    1,  337,   30,    1,    2, 1795,  261, 3721,    1,    1,   15,\n",
      "           38,    1,    2,   20,   89,    1,   19,   38,    1,    1,    1,  559,\n",
      "          119,  239,  955,    1, 3410,    2,   14,    1,  100,    1]])\n",
      "예측 : 두한\n"
     ]
    }
   ],
   "source": [
    "predict(\"쩝,그거야뭐돈이생기면갚으면되는거지.아저…이거봐,우리저,나가자고어?저녁이나같이먹어.일환이도.어?\") # 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5418,   10,    1,    1,   17,    1,  119, 1427,    3, 2085,    1, 1046,\n",
      "            5, 1028]])\n",
      "예측 : 이승만\n"
     ]
    }
   ],
   "source": [
    "# 다른 사이트에서 대사 갖고오기: 베르길리우스 \n",
    "# https://www.youtube.com/shorts/Q8pWmVp0v44\n",
    "predict(\"회사는 자아실현의 공간이나 사상을 설파하는 장소가 아니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TEXT_017_220_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
